{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/vadim/playlist_generation/data/random_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('{}/tracks.csv'.format(data_dir), index_col=0)\n",
    "artists = pd.read_csv('{}/artists.csv'.format(data_dir), index_col=0)\n",
    "albums = pd.read_csv('{}/albums.csv'.format(data_dir), index_col=0)\n",
    "transactions = pd.read_csv('{}/transactions.csv'.format(data_dir), index_col=0)\n",
    "playlists = pd.read_csv('{}/playlists.csv'.format(data_dir), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_dataset(transactions, tracks, playlists):\n",
    "    full_dataset = pd.merge(transactions, tracks, how='left', on='trackid')\n",
    "    full_dataset = pd.merge(full_dataset, playlists, how='left', on='pid')\n",
    "    return full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>trackid</th>\n",
       "      <th>popular</th>\n",
       "      <th>artistid</th>\n",
       "      <th>albumid</th>\n",
       "      <th>name</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>822314</td>\n",
       "      <td>1149</td>\n",
       "      <td>6600</td>\n",
       "      <td>636</td>\n",
       "      <td>821</td>\n",
       "      <td>going out</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>822314</td>\n",
       "      <td>230</td>\n",
       "      <td>5313</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>going out</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822314</td>\n",
       "      <td>4937</td>\n",
       "      <td>4965</td>\n",
       "      <td>876</td>\n",
       "      <td>3355</td>\n",
       "      <td>going out</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>822595</td>\n",
       "      <td>23973</td>\n",
       "      <td>96</td>\n",
       "      <td>7340</td>\n",
       "      <td>14054</td>\n",
       "      <td>FALL '16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>822595</td>\n",
       "      <td>4171</td>\n",
       "      <td>694</td>\n",
       "      <td>1845</td>\n",
       "      <td>2862</td>\n",
       "      <td>FALL '16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pid  trackid  popular  artistid  albumid       name  num_followers  \\\n",
       "0  822314     1149     6600       636      821  going out              1   \n",
       "1  822314      230     5313        95      138  going out              1   \n",
       "2  822314     4937     4965       876     3355  going out              1   \n",
       "3  822595    23973       96      7340    14054   FALL '16              5   \n",
       "4  822595     4171      694      1845     2862   FALL '16              5   \n",
       "\n",
       "   rating  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset = get_full_dataset(transactions, tracks, playlists)\n",
    "full_dataset['rating'] = 1\n",
    "full_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polara.recommender.models import RecommenderModel\n",
    "from polara.recommender.data import RecommenderData\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalCollectiveEmbeddings(RecommenderModel):\n",
    "    import scipy.sparse\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(LocalCollectiveEmbeddings, self).__init__(*args, **kwargs)\n",
    "        self.method = 'LCE'\n",
    "        \n",
    "    def reindex_content(self, content_data, col, sort=True, inplace=True):\n",
    "        grouper = content_data.groupby(col, sort=sort).grouper\n",
    "        new_val = grouper.group_info[1]\n",
    "        old_val = grouper.levels[0]\n",
    "        val_transform = pd.DataFrame({'old': old_val, 'new': new_val})\n",
    "        new_data = grouper.group_info[0]\n",
    "\n",
    "        if inplace:\n",
    "            result = val_transform\n",
    "            content_data.loc[:, col] = new_data\n",
    "        else:\n",
    "            result = (new_data, val_transform)\n",
    "        return result\n",
    "        \n",
    "    def reindex_content_columns(self, content_data, columns):\n",
    "        index_content = {}\n",
    "        for col in columns:\n",
    "            index_content[col] = self.reindex_content(content_data, col)\n",
    "        return index_content\n",
    "    \n",
    "    def get_train_content(self, content_data):\n",
    "        self.train_content = content_data\n",
    "    \n",
    "    def get_content_shape(self):\n",
    "        self.content_shape = {}\n",
    "        for col in self.train_content.columns:\n",
    "            self.content_shape[col] = self.train_content[col].max() + 1\n",
    "\n",
    "    def get_training_content_matrix(self):\n",
    "        self.get_content_shape()\n",
    "        idx_pid = self.data.training[self.data.fields[0]].values\n",
    "        val = np.ones(self.data.training.shape[0])\n",
    "        \n",
    "        i = 0\n",
    "        Xu = []\n",
    "        \n",
    "        for col in self.train_content.columns:\n",
    "            idx = self.train_content[col].values\n",
    "            shp = (idx_pid.max() + 1, \n",
    "                   self.content_shape[col])\n",
    "        \n",
    "            Xu_new = sparse.csr_matrix((val, (idx_pid, idx)), \n",
    "                                    shape=shp)\n",
    "            \n",
    "            if i == 0:\n",
    "                Xu = Xu_new\n",
    "            else:\n",
    "                Xu = sparse.hstack((Xu, Xu_new))\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        return Xu\n",
    "    \n",
    "    def get_test_content_matrix(self):\n",
    "        self.get_content_shape()\n",
    "        idx_pid = self.data.test.testset[self.data.fields[0]].values\n",
    "        val = np.ones(self.data.test.testset.shape[0])\n",
    "        \n",
    "        i = 0\n",
    "        Xu = []\n",
    "        \n",
    "        for col in self.train_content.columns:\n",
    "            idx = self.data.test.testset[col].values\n",
    "            shp = (idx_pid.max() + 1, \n",
    "                   self.content_shape[col])\n",
    "        \n",
    "            Xu_new = sparse.csr_matrix((val, (idx_pid, idx)), \n",
    "                                       shape=shp)\n",
    "            \n",
    "            if i == 0:\n",
    "                Xu = Xu_new\n",
    "            else:\n",
    "                Xu = sparse.hstack((Xu, Xu_new))\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        \n",
    "        return Xu\n",
    "        \n",
    "        \n",
    "    def construct_A(self, X, k=15, binary=False):\n",
    "        nbrs = NearestNeighbors(n_neighbors=1 + k).fit(X)\n",
    "        if binary:\n",
    "            A = nbrs.kneighbors_graph(X)\n",
    "        else:\n",
    "            A = nbrs.kneighbors_graph(X, mode='distance')\n",
    "            \n",
    "        return A\n",
    "    \n",
    "    def build(self, content_data, \n",
    "              k=10, alpha=0.1, beta=0.05, lamb=0.001, \n",
    "              epsilon=0.01, maxiter=150, verbose=True):\n",
    "        \n",
    "        self.get_train_content(content_data)\n",
    "        \n",
    "        R = self.get_training_matrix(dtype='float64')\n",
    "        Xu = self.get_training_content_matrix()\n",
    "        A = self.construct_A(Xu, k)\n",
    "        \n",
    "        n = R.shape[0]\n",
    "        v1 = R.shape[1]\n",
    "        v2 = Xu.shape[1]\n",
    "        \n",
    "        W = np.abs(sparse.rand(n, k, 0.5, 'csr', dtype=R.dtype))\n",
    "        Hi = np.abs(sparse.rand(k, v1, 0.5, 'csr', dtype=R.dtype))\n",
    "        Hu = np.abs(sparse.rand(k, v2, 0.5, 'csr', dtype=R.dtype))\n",
    "            \n",
    "        D = sparse.dia_matrix((A.sum(axis=0), 0), A.shape)\n",
    "\n",
    "        \n",
    "        gamma = 1. - alpha\n",
    "        \n",
    "        trRtR = tr(R, R)\n",
    "        trXutXu = tr(Xu, Xu)\n",
    "\n",
    "        WtW = W.T.dot(W)\n",
    "        WtR = W.T.dot(R)\n",
    "        WtXu = W.T.dot(Xu)\n",
    "        WtWHi = WtW.dot(Hi)\n",
    "        WtWHu = WtW.dot(Hu)\n",
    "        DW = D.dot(W)\n",
    "        AW = A.dot(W)\n",
    "\n",
    "        itNum = 1\n",
    "        delta = 2.0 * epsilon\n",
    "\n",
    "        ObjHist = []\n",
    "\n",
    "        while True:\n",
    "            \n",
    "            # update H\n",
    "            Hi_1 = np.divide(\n",
    "                (alpha * WtR), (alpha * WtWHi + lamb * Hi).maximum(1e-6))\n",
    "    \n",
    "            Hi = Hi.multiply(Hi_1)\n",
    "            \n",
    "            Hu_1 = np.divide(\n",
    "                (gamma * WtXu), (gamma * WtWHu + lamb * Hu).maximum(1e-6))\n",
    "            Hu = Hu.multiply(Hu_1)\n",
    "            \n",
    "            # update W\n",
    "            W_t1 = alpha * R.dot(Hi.T) + gamma * Xu.dot(Hu.T) + beta * AW\n",
    "            \n",
    "            W_t2 = alpha * W.dot(Hi.dot(Hi.T)) + gamma * \\\n",
    "            W.dot(Hu.dot(Hu.T)) + beta * DW + lamb * W\n",
    "            \n",
    "            W_t3 = np.divide(W_t1, (W_t2).maximum(1e-6))\n",
    "            W = W.multiply(W_t3)\n",
    "\n",
    "            # calculate objective function\n",
    "            WtW = W.T.dot(W)\n",
    "            WtR = W.T.dot(R)\n",
    "            WtXu = W.T.dot(Xu)\n",
    "            WtWHi = WtW.dot(Hi)\n",
    "            WtWHu = WtW.dot(Hu)\n",
    "            DW = D.dot(W)\n",
    "            AW = A.dot(W)\n",
    "\n",
    "            tr1 = alpha * (trRtR - 2. * tr(Hi, WtR) + tr(Hi, WtWHi))\n",
    "            tr2 = gamma * (trXutXu - 2. * tr(Hu, WtXu) + tr(Hu, WtWHu))\n",
    "            tr3 = beta * (tr(W, DW) - tr(W, AW))\n",
    "            tr4 = lamb * (WtW.diagonal().sum() + tr(Hi, Hi) + tr(Hu, Hu))\n",
    "\n",
    "            Obj = tr1 + tr2 + tr3 + tr4\n",
    "            ObjHist.append(Obj)\n",
    "\n",
    "            if itNum > 1:\n",
    "                delta = abs(ObjHist[-1] - ObjHist[-2])\n",
    "                if verbose:\n",
    "                    print (\"Iteration: \", itNum, \"Objective: \", Obj, \"Delta: \", delta)\n",
    "                if itNum > maxiter or delta < epsilon:\n",
    "                    break\n",
    "\n",
    "            itNum += 1\n",
    "            \n",
    "        self.W = W\n",
    "        self.Hu = Hu \n",
    "        self.Hi = Hi\n",
    "        \n",
    "        \n",
    "    def get_recommendations(self):\n",
    "        Xu = self.get_test_content_matrix()\n",
    "        Wt = np.linalg.lstsq(self.Hu.T.toarray(), Xu.T.toarray(), rcond=-1)[0]\n",
    "        R = Wt.T.dot(self.Hi.toarray())\n",
    "        return np.flip(np.argsort(R, axis=1), axis=1)[:self.topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_content(content_data, col, sort=True, inplace=True):\n",
    "    grouper = content_data.groupby(col, sort=sort).grouper\n",
    "    new_val = grouper.group_info[1]\n",
    "    old_val = grouper.levels[0]\n",
    "    val_transform = pd.DataFrame({'old': old_val, 'new': new_val})\n",
    "    new_data = grouper.group_info[0]\n",
    "\n",
    "    if inplace:\n",
    "        result = val_transform\n",
    "        content_data.loc[:, col] = new_data\n",
    "    else:\n",
    "        result = (new_data, val_transform)\n",
    "    return result\n",
    "        \n",
    "def reindex_content_columns(content_data, columns):\n",
    "    index_content = {}\n",
    "    for col in columns:\n",
    "        index_content[col] = reindex_content(content_data, col)\n",
    "    return index_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr(A, B):\n",
    "    x = A.multiply(B)\n",
    "    return (x.sum(axis=0)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_content = reindex_content_columns(full_dataset, ['artistid', 'albumid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "data_model = RecommenderData(full_dataset,'pid', 'trackid', 'rating', seed=0)\n",
    "data_model.prepare_training_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = LocalCollectiveEmbeddings(data_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/sparse/compressed.py:538: SparseEfficiencyWarning: Taking maximum (minimum) with > 0 (< 0) number results to a dense matrix.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "a.build(full_dataset[['artistid', 'albumid']], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_lce(data, n_splits=5, seed=1, test_size=0.05, topk=500, rank=10):\n",
    "    \n",
    "    index_content = reindex_content_columns(data, ['artistid', 'albumid'])\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, random_state=seed)\n",
    "    i = 1\n",
    "    scores = {'precision': [], 'recall': [], 'miss_rate': [], 'nDCG': []}\n",
    "    for users_ids, unseen_users_ids in kf.split(data['pid'].drop_duplicates()):\n",
    "        print('=========================Fold {}============================='.format(i))\n",
    "        i += 1\n",
    "        users = data['pid'].drop_duplicates().values[users_ids]\n",
    "        unseen_users = data['pid'].drop_duplicates().values[unseen_users_ids]\n",
    "        train = data.query('pid in @users')\n",
    "        test = data.query('pid in @unseen_users')\n",
    "        train_albums = train.albumid.unique()\n",
    "        train_artists = train.artistid.unique()\n",
    "        test = test.query('albumid in @train_albums')\n",
    "        test = test.query('artistid in @train_artists')\n",
    "        test_sampled = test.sample(frac=1-test_size, random_state=seed).sort_values('pid')\n",
    "        test_holdout = test[~test.index.isin(test_sampled.index)]\n",
    "        \n",
    "        data_model = RecommenderData(train,'pid', 'trackid', 'rating', seed=seed)\n",
    "        data_model.prepare_training_only()\n",
    "        lce = LocalCollectiveEmbeddings(data_model)\n",
    "        lce.build(train[['artistid', 'albumid']], verbose=False)\n",
    "        \n",
    "        data_model.set_test_data(testset=test_sampled, holdout=test_holdout, warm_start=True)\n",
    "        lce.switch_positive = 1\n",
    "        lce.topk = topk\n",
    "        relevance = lce.evaluate('relevance')\n",
    "        ranking = lce.evaluate('ranking')\n",
    "        \n",
    "        scores['precision'].append(relevance.precision)\n",
    "        scores['recall'].append(relevance.recall)\n",
    "        scores['miss_rate'].append(relevance.miss_rate)\n",
    "        scores['nDCG'].append(ranking.nDCG)\n",
    "        \n",
    "    result = pd.DataFrame(scores)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Fold 1=============================\n",
      "Preparing data...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/sparse/compressed.py:538: SparseEfficiencyWarning: Taking maximum (minimum) with > 0 (< 0) number results to a dense matrix.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 unique trackid's within 2 testset interactions were filtered. Reason: not in the training data.\n",
      "137 pid's were filtered out from testset. Reason: inconsistent with holdout.\n",
      "=========================Fold 2=============================\n",
      "Preparing data...\n",
      "Done.\n",
      "2 unique trackid's within 3 testset interactions were filtered. Reason: not in the training data.\n",
      "2 pid's were filtered out from holdout. Reason: inconsistent with testset.\n",
      "128 pid's were filtered out from testset. Reason: inconsistent with holdout.\n",
      "=========================Fold 3=============================\n",
      "Preparing data...\n",
      "Done.\n",
      "3 unique trackid's within 4 testset interactions were filtered. Reason: not in the training data.\n",
      "131 pid's were filtered out from testset. Reason: inconsistent with holdout.\n",
      "=========================Fold 4=============================\n",
      "Preparing data...\n",
      "Done.\n",
      "1 unique trackid's within 1 testset interactions were filtered. Reason: not in the training data.\n",
      "131 pid's were filtered out from testset. Reason: inconsistent with holdout.\n",
      "=========================Fold 5=============================\n",
      "Preparing data...\n",
      "Done.\n",
      "4 unique trackid's within 6 testset interactions were filtered. Reason: not in the training data.\n",
      "137 pid's were filtered out from testset. Reason: inconsistent with holdout.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>miss_rate</th>\n",
       "      <th>nDCG</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188345</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208832</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   miss_rate      nDCG  precision  recall\n",
       "0        0.0  0.184390        1.0     1.0\n",
       "1        0.0  0.125873        1.0     1.0\n",
       "2        0.0  0.188345        1.0     1.0\n",
       "3        0.0  0.208832        1.0     1.0\n",
       "4        0.0  0.193643        1.0     1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation_lce(full_dataset, test_size=0.009, topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
